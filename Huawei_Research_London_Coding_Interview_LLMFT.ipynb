{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/QinyanGong/2024RL/blob/main/Huawei_Research_London_Coding_Interview_LLMFT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e57a8f29-9121-4d34-ba00-f9b758636ca5",
      "metadata": {
        "id": "e57a8f29-9121-4d34-ba00-f9b758636ca5"
      },
      "source": [
        "# Building a Custom Trainer Based on Huggingface\n",
        "\n",
        "## Main Task\n",
        "In this second part, you need to implement a trainer based on Huggingface Trainer class.\n",
        "You need to extend the existing Trainer class of huggingface to use a different loss function.\n",
        "Below is the link to the documentation of the Trainer class: https://huggingface.co/docs/transformers/main/en/trainer\n",
        "Note that you need 4-8GB of CPU RAM.\n",
        "We do not expect to run the full training, but only to implement the necessary components for training\n",
        "\n",
        "## LLM\n",
        "For this excersice you need to use the Qwen/Qwen1.5-0.5B-Chat model.\n",
        "Note: THIS IS A CHAT MODEL. Please read carefully how to use this model in: https://huggingface.co/Qwen/Qwen1.5-0.5B-Chat\n",
        "\n",
        "## Dataset\n",
        "\n",
        "You are given the training dataset where each example in the dataset is a dictionary that contains two keys:\n",
        "* The first key is 'text', which contains a multi-turn conversation in natural language that will be used as input to the llm. The text is in the form [list[dict]], which is a list of dictionaries. Each dictionary has two keys; the first is the role, which can be 'system', 'user', or 'assistant', the second is 'content', which is the content of the message. 'system' corresponds to the system prompt of the llm, 'user' corresponds to the text that is inputted to the llm, and 'assistant' corresponds to the response of the llm.\n",
        "```\n",
        "chat = [\n",
        "    {\"role\": \"system\", \"content\": \"You a helpful assisant\"},\n",
        "    {\"role\": \"user\", \"content\": \"Hello, how are you?\"},\n",
        "    {\"role\": \"assistant\", \"content\": \"Fine. How can I help you today?\"},\n",
        "    {\"role\": \"user\", \"content\": \"What is the circumference of earth?\"},\n",
        "    {\"role\": \"assistant\", \"content\": \"It is 40,075 kms.\"},]\n",
        "```\n",
        "\n",
        "* The second key is 'reward', which is a scalar number between -1 and 1, which indicates whether the specific example is good or not\n",
        "\n",
        "## Optimization Objective\n",
        "\n",
        "You need to implement the undiscounted REINFORCE algorithm. It is an extension of SFT that takes into account the reward that is assigned to the trajectory.\n",
        "The loss function is\n",
        "$$ L = - \\frac{1}{B} \\sum_{b \\in B}\\sum_{t \\in seq[b]} (reward[b] * \\log p(x[b][t] | x[b][:t])) \\textrm{ if $x[b][t]$ belongs is one of the assistant's tokens}$$\n",
        "\n",
        "The loss is 0 otherwise.\n",
        "Practically that means that give the aforementioned chat example, the loss is not 0 only for the following pieces of text\n",
        "```\n",
        "{\"role\": \"assistant\", \"content\": \"Fine. How can I help you today?\"},\n",
        "and\n",
        "{\"role\": \"assistant\", \"content\": \"It is 40,075 kms.\"}\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "# 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\n",
        "notebook_login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359,
          "referenced_widgets": [
            "f525d64631c34235b286a043fbc996ea",
            "48587a9b43e84380ba8596b3e56e7f79",
            "043b24de404846d29e0d16e78e1a74df",
            "aa007d625b454f2499b9dc2acb977a33",
            "a4346279e3d74718b31e01e6c3db028a",
            "808be3cdeadc4d979bb91b432a76130a",
            "c3578bef74de4f40896f9fd4bd5d6c9e",
            "fd466f5a7464431b9445f095888cf331",
            "ddd8515e42564c8cb99f350335bed4b2",
            "8d30d2a849a547dba4aa14cf90a9f64c",
            "0311375d26b04f7c8603323a243ad11a",
            "af8044c79f44437a8e8be607802947a2",
            "c87d4a33fbf945d3af3644709e012107",
            "87ac318249954581a64a50f7a83bf6b8",
            "e218fe3cb6c94ef1bd71a9c4a31b0d71",
            "d84afbcb6eda46cbb40b66e84f353862",
            "95947a14e94642d18c9741de8dedb79e"
          ]
        },
        "id": "lfQrJCY_TT-C",
        "outputId": "14fdbeff-0a37-4bcb-f7b0-4c80f1740301"
      },
      "id": "lfQrJCY_TT-C",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f525d64631c34235b286a043fbc996ea"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2ff6956-eae3-4e37-8bf5-cace49a53063",
      "metadata": {
        "id": "c2ff6956-eae3-4e37-8bf5-cace49a53063"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import transformers\n",
        "import torch\n",
        "\n",
        "model_id = \"Qwen/Qwen1.5-0.5B-Chat\"\n",
        "dtype = torch.bfloat16\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    device_map=\"cuda\",\n",
        "    torch_dtype=dtype,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a96ff93f-2feb-4941-a4af-b0c083126624",
      "metadata": {
        "id": "a96ff93f-2feb-4941-a4af-b0c083126624"
      },
      "source": [
        "You are give the following data, which has to be loaded in order to be used by the huggingface's transformers Trainer. We recommend using the datasets library\n",
        "https://huggingface.co/docs/datasets/en/index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3babd8b0-4494-4cdf-9c23-11b52c9b20d2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3babd8b0-4494-4cdf-9c23-11b52c9b20d2",
        "outputId": "c7a26a8e-be7a-459b-c2d9-561a8a833fe4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'text': [{'role': 'system', 'content': 'You a helpful assisant'}, {'role': 'user', 'content': 'Hello, how are you?'}, {'role': 'assistant', 'content': 'Fine. How can I help you today?'}, {'role': 'user', 'content': 'What is the circumference of earth?'}, {'role': 'assistant', 'content': 'It is 40,075 kms.'}], 'reward': 1}, {'text': [{'role': 'system', 'content': 'You a helpful assisant'}, {'role': 'user', 'content': 'Hello, how are you?'}, {'role': 'assistant', 'content': 'Fine. How can I help you today?'}, {'role': 'user', 'content': 'What is the shape of earth?'}, {'role': 'assistant', 'content': 'Earth is a square'}], 'reward': -1}]\n"
          ]
        }
      ],
      "source": [
        "data =[{'text':\n",
        "    [{\"role\": \"system\", \"content\": \"You a helpful assisant\"},\n",
        "    {\"role\": \"user\", \"content\": \"Hello, how are you?\"},\n",
        "    {\"role\": \"assistant\", \"content\": \"Fine. How can I help you today?\"},\n",
        "    {\"role\": \"user\", \"content\": \"What is the circumference of earth?\"},\n",
        "    {\"role\": \"assistant\", \"content\": \"It is 40,075 kms.\"}],\n",
        "         'reward': 1},\n",
        "        {'text':\n",
        "    [{\"role\": \"system\", \"content\": \"You a helpful assisant\"},\n",
        "    {\"role\": \"user\", \"content\": \"Hello, how are you?\"},\n",
        "    {\"role\": \"assistant\", \"content\": \"Fine. How can I help you today?\"},\n",
        "    {\"role\": \"user\", \"content\": \"What is the shape of earth?\"},\n",
        "    {\"role\": \"assistant\", \"content\": \"Earth is a square\"}],\n",
        "         'reward': -1}]\n",
        "print(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59f84a36-081b-4807-85f2-8ca2d5d3c0ac",
      "metadata": {
        "id": "59f84a36-081b-4807-85f2-8ca2d5d3c0ac"
      },
      "source": [
        "Please note that we do not expect to run the full training. We will just check whether the code is generally correct. You are free to use any library such as transformers, trl, etc for your implementation."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "from transformers import Trainer\n",
        "\n",
        "class CustomTrainer(Trainer):\n",
        "    def compute_loss(self, model, inputs, return_outputs=False):\n",
        "        labels = inputs.pop(\"labels\")\n",
        "        # forward pass\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.get(\"logits\")\n",
        "        # compute custom loss for 3 labels with different weights\n",
        "        loss_fct = nn.CrossEntropyLoss(weight=torch.tensor([1.0, 2.0, 3.0], device=model.device))\n",
        "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
        "        return (loss, outputs) if return_outputs else loss"
      ],
      "metadata": {
        "id": "8rdlfz_CJ7V3"
      },
      "id": "8rdlfz_CJ7V3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "def pad_tensor(tensor, max_length):\n",
        "    \"\"\"\n",
        "    Pads or truncates a tensor to the specified max_length.\n",
        "    If the tensor is shorter than max_length, it pads with 0s.\n",
        "    If the tensor is longer than max_length, it truncates.\n",
        "    \"\"\"\n",
        "    if tensor.size(0) < max_length:\n",
        "        # Pad tensor if it's shorter than max_length\n",
        "        return F.pad(tensor, (0, max_length - tensor.size(0)), value=0)\n",
        "    else:\n",
        "        # Truncate tensor if it's longer than max_length\n",
        "        return tensor[:max_length]"
      ],
      "metadata": {
        "id": "Zs3OzFWdo6VX"
      },
      "id": "Zs3OzFWdo6VX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_data(data):\n",
        "    input_ids_list = []\n",
        "    labels_list = []\n",
        "    role_ids_list = []\n",
        "    rewards_list = []\n",
        "    #  data is a list\n",
        "    for conversation in data:\n",
        "        reward = conversation['reward']\n",
        "        full_text = \"\"\n",
        "        role_ids = []\n",
        "\n",
        "        # Construct the sequence for tokenization\n",
        "        for turn in conversation['text']:\n",
        "            content = turn['content']\n",
        "            full_text += content + \" \"  # Concatenate the conversation\n",
        "\n",
        "            # Role IDs: 1 for assistant tokens, 0 for others (system and user)\n",
        "            # Use role ids as masks\n",
        "            role_id = 1 if turn['role'] == 'assistant' else 0\n",
        "            role_ids.extend([role_id] * len(tokenizer.tokenize(content)))\n",
        "\n",
        "\n",
        "        # Tokenize the entire conversation\n",
        "        inputs = tokenizer(full_text, padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"pt\")\n",
        "\n",
        "        # Append the input_ids and attention masks to the corresponding lists\n",
        "        input_ids_list.append(inputs['input_ids'].squeeze(0).to('cuda'))  # Remove batch dimension\n",
        "        role_ids = pad_tensor(torch.tensor(role_ids), inputs['input_ids'].size(-1)).to('cuda')\n",
        "        role_ids_list.append(torch.tensor(role_ids[:inputs['input_ids'].size(-1)]))  # Match length to input_ids\n",
        "\n",
        "        # Assign the same reward for all tokens (for the assistant's tokens)\n",
        "        rewards = torch.tensor([reward] * len(role_ids)).to('cuda')\n",
        "        rewards_list.append(rewards[:inputs['input_ids'].size(-1)])  # Match length to input_ids\n",
        "        # Create labels list where non-assistant tokens are replaced with pad_token_id\n",
        "        labels = inputs['input_ids'].clone()\n",
        "        # print(labels)\n",
        "        # print(role_ids)\n",
        "        labels[torch.tensor(role_ids).unsqueeze(0) == 0] = tokenizer.pad_token_id\n",
        "        labels_list.append(labels.to('cuda'))\n",
        "\n",
        "    return input_ids_list, role_ids_list, rewards_list, labels_list"
      ],
      "metadata": {
        "id": "hWTqdWBBN1jq"
      },
      "id": "hWTqdWBBN1jq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Process the data\n",
        "input_ids, role_ids, rewards, labels = process_data(data)\n",
        "inputs = {\n",
        "    'input_ids': input_ids,   # Tokenized sequences\n",
        "    'role_ids': role_ids,     # 1 for assistant tokens, 0 for user/system\n",
        "    'labels': labels,      # For language models, input and labels are usually the same\n",
        "    'rewards': rewards        # Reward associated with each sequence\n",
        "}\n",
        "inputs"
      ],
      "metadata": {
        "id": "BB5MKdgeO4TW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76e839de-6e16-4b25-9665-98113c3510bb"
      },
      "id": "BB5MKdgeO4TW",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-262-996f0ebfa375>:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  role_ids_list.append(torch.tensor(role_ids[:inputs['input_ids'].size(-1)]))  # Match length to input_ids\n",
            "<ipython-input-262-996f0ebfa375>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  labels[torch.tensor(role_ids).unsqueeze(0) == 0] = tokenizer.pad_token_id\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [tensor([  2610,    264,  10950,   1071,    285,    517,  21927,     11,   1246,\n",
              "             525,    498,     30,  30153,     13,   2585,    646,    358,   1492,\n",
              "             498,   3351,     30,   3555,    374,    279,  74926,    315,   9393,\n",
              "              30,   1084,    374,    220,     19,     15,     11,     15,     22,\n",
              "              20,  96677,     13,    220, 151643, 151643, 151643, 151643, 151643,\n",
              "          151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
              "          151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
              "          151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
              "          151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
              "          151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
              "          151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
              "          151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
              "          151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
              "          151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
              "          151643, 151643], device='cuda:0'),\n",
              "  tensor([  2610,    264,  10950,   1071,    285,    517,  21927,     11,   1246,\n",
              "             525,    498,     30,  30153,     13,   2585,    646,    358,   1492,\n",
              "             498,   3351,     30,   3555,    374,    279,   6083,    315,   9393,\n",
              "              30,   9237,    374,    264,   9334,    220, 151643, 151643, 151643,\n",
              "          151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
              "          151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
              "          151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
              "          151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
              "          151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
              "          151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
              "          151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
              "          151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
              "          151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
              "          151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
              "          151643, 151643], device='cuda:0')],\n",
              " 'role_ids': [tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
              "          0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0'),\n",
              "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
              "          0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')],\n",
              " 'labels': [tensor([[151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
              "           151643, 151643, 151643,  30153,     13,   2585,    646,    358,   1492,\n",
              "              498,   3351,     30, 151643, 151643, 151643, 151643, 151643, 151643,\n",
              "           151643,   1084,    374,    220,     19,     15,     11,     15,     22,\n",
              "               20,  96677,     13, 151643, 151643, 151643, 151643, 151643, 151643,\n",
              "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
              "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
              "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
              "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
              "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
              "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
              "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
              "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
              "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
              "           151643, 151643]], device='cuda:0'),\n",
              "  tensor([[151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
              "           151643, 151643, 151643,  30153,     13,   2585,    646,    358,   1492,\n",
              "              498,   3351,     30, 151643, 151643, 151643, 151643, 151643, 151643,\n",
              "           151643,   9237,    374,    264,   9334, 151643, 151643, 151643, 151643,\n",
              "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
              "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
              "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
              "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
              "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
              "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
              "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
              "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
              "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
              "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
              "           151643, 151643]], device='cuda:0')],\n",
              " 'rewards': [tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0'),\n",
              "  tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
              "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
              "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
              "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
              "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
              "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
              "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
              "          -1, -1], device='cuda:0')]}"
            ]
          },
          "metadata": {},
          "execution_count": 263
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a=[1,2,3,4,5,6,7,8,9]\n",
        "b=[1,0,0,0,0,0,0,0,0]\n",
        "a=torch.tensor(a)\n",
        "b=torch.tensor(b)\n",
        "a[b==0]=100\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iakqn6xHbcVW",
        "outputId": "864cf352-de8d-4343-aea4-726880223354"
      },
      "id": "Iakqn6xHbcVW",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  1, 100, 100, 100, 100, 100, 100, 100, 100])"
            ]
          },
          "metadata": {},
          "execution_count": 264
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class REINFORCETrainer(Trainer):\n",
        "  def compute_loss(self, model, inputs, return_outputs=False):\n",
        "\n",
        "    # forward pass\n",
        "    print(inputs)\n",
        "    outputs = model(**inputs)\n",
        "    labels = inputs.pop(\"labels\")\n",
        "    logits = outputs.get(\"logits\")\n",
        "    rewards = inputs.get(\"rewards\")\n",
        "    # Compute the log-probabilities of the predicted tokens\n",
        "    log_probs = nn.functional.log_softmax(logits, dim=-1)\n",
        "    print(log_probs.size()) # [batch, words, idx]\n",
        "    # Initialize the loss as zero\n",
        "    loss = 0\n",
        "    role_ids = inputs.get(\"role_ids\")\n",
        "    print(role_ids)\n",
        "    # Loop through the batch\n",
        "    for batch_idx in range(log_probs.size(0)):\n",
        "      seq_log_probs = log_probs[batch_idx]     # Log probs for the current sequence\n",
        "      seq_labels = labels[batch_idx]           # True labels for the current sequence\n",
        "      seq_role_ids = role_ids[batch_idx]       # Role identifiers for the current sequence (assistant/user)\n",
        "      reward = rewards[batch_idx]              # Reward for the current sequence\n",
        "\n",
        "      # Loop through the sequence\n",
        "      for t in range(seq_log_probs.size(0)):\n",
        "        if seq_role_ids[t] == 1:  # Only compute loss for assistant-generated tokens\n",
        "          token_log_prob = seq_log_probs[t, seq_labels[t]]  # Log prob of the correct token\n",
        "          loss -= reward * token_log_prob  # REINFORCE loss for the assistant's token\n",
        "\n",
        "      # Normalize loss by batch size\n",
        "      loss = loss / log_probs.size(0)\n",
        "\n",
        "      return (loss, outputs) if return_outputs else loss"
      ],
      "metadata": {
        "id": "JZZjSScCNBx-"
      },
      "id": "JZZjSScCNBx-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_loss(model, inputs, return_outputs=False):\n",
        "\n",
        "    # forward pass\n",
        "    # print(inputs)\n",
        "    model_inputs = {\n",
        "        'input_ids': inputs['input_ids'],\n",
        "        'labels': inputs['labels'],\n",
        "        'attention_mask': torch.ones_like(inputs['input_ids'],device='cuda')\n",
        "    }\n",
        "    outputs = model(**model_inputs)\n",
        "    labels = inputs[\"labels\"]\n",
        "    logits = outputs.get(\"logits\")\n",
        "    rewards = inputs[\"rewards\"]\n",
        "    # Compute the log-probabilities of the predicted tokens\n",
        "    log_probs = nn.functional.log_softmax(logits, dim=-1)\n",
        "    # print(log_probs.size()) # [batch, words, idx]\n",
        "    # Initialize the loss as zero\n",
        "    loss = 0\n",
        "    role_ids = inputs[\"role_ids\"]\n",
        "    # Loop through the batch\n",
        "    for batch_idx in range(log_probs.size(0)):\n",
        "      seq_log_probs = log_probs[batch_idx]     # Log probs for the current sequence\n",
        "      seq_labels = labels[batch_idx]           # True labels for the current sequence\n",
        "      seq_role_ids = role_ids[batch_idx]       # Role identifiers for the current sequence (assistant/user)\n",
        "      reward = rewards[batch_idx]              # Reward for the current sequence\n",
        "      # print(f'seq_log_probs: {seq_log_probs.shape}')\n",
        "      # Loop through the sequence\n",
        "      for t in range(seq_log_probs.size(0)):\n",
        "        if seq_role_ids[t] == 1:  # Only compute loss for assistant-generated tokens\n",
        "          token_log_prob = seq_log_probs[t,seq_labels.squeeze(0)[t]]  # Log prob of the correct token\n",
        "          loss -= reward[t] * token_log_prob  # REINFORCE loss for the assistant's token\n",
        "      # print(f'log prob: {token_log_prob}')\n",
        "      # Normalize loss by batch size\n",
        "      loss = loss / log_probs.size(0)\n",
        "      # print(f'loss:{loss}')\n",
        "\n",
        "      return loss"
      ],
      "metadata": {
        "id": "x4iVz9dDnr5-"
      },
      "id": "x4iVz9dDnr5-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainerCallback\n",
        "\n",
        "class EarlyStoppingCallback(TrainerCallback):\n",
        "    def __init__(self, num_steps=10):\n",
        "        self.num_steps = num_steps\n",
        "\n",
        "    def on_step_end(self, args, state, control, **kwargs):\n",
        "        if state.global_step >= self.num_steps:\n",
        "            return {\"should_training_stop\": True}\n",
        "        else:\n",
        "            return {}"
      ],
      "metadata": {
        "id": "ySc0kTdvMlw_"
      },
      "id": "ySc0kTdvMlw_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"new-chat\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=2,\n",
        "    per_device_eval_batch_size=2,\n",
        "    num_train_epochs=2,\n",
        "    weight_decay=0.01,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    push_to_hub=True,\n",
        ")"
      ],
      "metadata": {
        "id": "L2HK_yoiMtRl"
      },
      "id": "L2HK_yoiMtRl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "class ChatDataset(Dataset):\n",
        "    def __init__(self, input_ids_list, role_ids_list, rewards_list, labels):\n",
        "        self.input_ids_list = input_ids_list\n",
        "        self.role_ids_list = role_ids_list\n",
        "        self.rewards_list = rewards_list\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {\n",
        "            'input_ids': self.input_ids_list[idx],\n",
        "            'role_ids': self.role_ids_list[idx],\n",
        "            'labels': self.labels[idx],\n",
        "            'rewards': self.rewards_list[idx]\n",
        "        }\n",
        "        return item\n",
        "\n",
        "# Create an instance of the dataset\n",
        "chat_dataset = ChatDataset(input_ids, role_ids, rewards,labels)\n",
        "train_loader = torch.utils.data.DataLoader(chat_dataset, batch_size=2, shuffle=True)"
      ],
      "metadata": {
        "id": "Mebb2Om2Pd0H"
      },
      "id": "Mebb2Om2Pd0H",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_dataset[0]\n",
        "next(iter(train_loader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "vK4o0ca4BX0H",
        "outputId": "4460c8ea-af6c-4493-f0c7-14c11fecc086"
      },
      "id": "vK4o0ca4BX0H",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[  2610,    264,  10950,   1071,    285,    517,  21927,     11,   1246,\n",
              "             525,    498,     30,  30153,     13,   2585,    646,    358,   1492,\n",
              "             498,   3351,     30,   3555,    374,    279,  74926,    315,   9393,\n",
              "              30,   1084,    374,    220,     19,     15,     11,     15,     22,\n",
              "              20,  96677,     13,    220, 151643, 151643, 151643, 151643, 151643,\n",
              "          151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
              "          151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
              "          151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
              "          151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
              "          151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
              "          151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
              "          151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
              "          151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
              "          151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
              "          151643, 151643],\n",
              "         [  2610,    264,  10950,   1071,    285,    517,  21927,     11,   1246,\n",
              "             525,    498,     30,  30153,     13,   2585,    646,    358,   1492,\n",
              "             498,   3351,     30,   3555,    374,    279,   6083,    315,   9393,\n",
              "              30,   9237,    374,    264,   9334,    220, 151643, 151643, 151643,\n",
              "          151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
              "          151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
              "          151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
              "          151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
              "          151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
              "          151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
              "          151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
              "          151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
              "          151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
              "          151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
              "          151643, 151643]], device='cuda:0'),\n",
              " 'role_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
              "          0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0],\n",
              "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
              "          0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0'),\n",
              " 'labels': tensor([[[151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
              "           151643, 151643, 151643, 151643,  30153,     13,   2585,    646,\n",
              "              358,   1492,    498,   3351,     30, 151643, 151643, 151643,\n",
              "           151643, 151643, 151643, 151643,   1084,    374,    220,     19,\n",
              "               15,     11,     15,     22,     20,  96677,     13, 151643,\n",
              "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
              "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
              "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
              "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
              "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
              "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
              "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
              "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
              "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
              "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
              "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643]],\n",
              " \n",
              "         [[151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
              "           151643, 151643, 151643, 151643,  30153,     13,   2585,    646,\n",
              "              358,   1492,    498,   3351,     30, 151643, 151643, 151643,\n",
              "           151643, 151643, 151643, 151643,   9237,    374,    264,   9334,\n",
              "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
              "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
              "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
              "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
              "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
              "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
              "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
              "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
              "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
              "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
              "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
              "           151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643]]],\n",
              "        device='cuda:0'),\n",
              " 'rewards': tensor([[ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
              "           1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
              "           1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
              "           1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
              "           1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
              "           1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
              "           1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
              "           1,  1],\n",
              "         [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
              "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
              "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
              "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
              "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
              "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
              "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
              "          -1, -1]], device='cuda:0')}"
            ]
          },
          "metadata": {},
          "execution_count": 270
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import AdamW\n",
        "# Optimizer\n",
        "optimizer = AdamW(model.parameters(), lr=1e-4)\n",
        "\n",
        "for epoch in range(10):\n",
        "    model.train()\n",
        "\n",
        "    for batch in train_loader:\n",
        "        # do the forward path\n",
        "        generated_ids = model.generate(batch['input_ids'],max_new_tokens=512)\n",
        "        # generated_ids = [output_ids[len(input_ids):] for input_ids, output_ids in zip(batch.input_ids, generated_ids)]\n",
        "        # response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "\n",
        "        # calculate the loss\n",
        "        loss = compute_loss(model, batch)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        print(f\"Epoch {epoch}, Loss: {loss.item()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2BvDmR3QkTq_",
        "outputId": "290e2799-e91d-4532-d527-75df0a60b163"
      },
      "id": "2BvDmR3QkTq_",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 55.70682144165039\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 21.333810806274414\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2, Loss: 16.612850189208984\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3, Loss: 1.5350146293640137\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4, Loss: -5.284585952758789\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5, Loss: -28.238998413085938\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6, Loss: -75.381591796875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7, Loss: -209.03271484375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8, Loss: -273.06427001953125\n",
            "Epoch 9, Loss: -315.2392578125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Trainer instance\n",
        "trainer = REINFORCETrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=chat_dataset,\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "# Start training\n",
        "trainer.train()\n",
        "\n",
        "# Optionally, evaluate the model\n",
        "trainer.evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lD4owvcK-_J",
        "outputId": "309fbac8-7fad-4a00-c407-5f62fea20a77",
        "collapsed": true
      },
      "id": "8lD4owvcK-_J",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[  2610,    264,  10950,   1071,    285,    517,  21927,     11,   1246,\n",
            "            525,    498,     30,  30153,     13,   2585,    646,    358,   1492,\n",
            "            498,   3351,     30,   3555,    374,    279,  74926,    315,   9393,\n",
            "             30,   1084,    374,    220,     19,     15,     11,     15,     22,\n",
            "             20,  96677,     13,    220, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643],\n",
            "        [  2610,    264,  10950,   1071,    285,    517,  21927,     11,   1246,\n",
            "            525,    498,     30,  30153,     13,   2585,    646,    358,   1492,\n",
            "            498,   3351,     30,   3555,    374,    279,   6083,    315,   9393,\n",
            "             30,   9237,    374,    264,   9334,    220, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643]], device='cuda:0'), 'labels': tensor([[[151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "          151643, 151643, 151643, 151643,  30153,     13,   2585,    646,\n",
            "             358,   1492,    498,   3351,     30, 151643, 151643, 151643,\n",
            "          151643, 151643, 151643, 151643,   1084,    374,    220,     19,\n",
            "              15,     11,     15,     22,     20,  96677,     13,    220,\n",
            "          151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "          151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "          151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "          151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "          151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "          151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "          151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "          151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "          151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "          151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "          151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643]],\n",
            "\n",
            "        [[151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "          151643, 151643, 151643, 151643,  30153,     13,   2585,    646,\n",
            "             358,   1492,    498,   3351,     30, 151643, 151643, 151643,\n",
            "          151643, 151643, 151643, 151643,   9237,    374,    264,   9334,\n",
            "             220, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "          151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "          151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "          151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "          151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "          151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "          151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "          151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "          151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "          151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "          151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "          151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643]]],\n",
            "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}\n",
            "torch.Size([2, 128, 151936])\n",
            "None\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'NoneType' object is not subscriptable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-126-73625d87c1b1>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Start training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Optionally, evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1927\u001b[0m                 \u001b[0;31m# Disable progress bars when uploading models during checkpoints to avoid polluting stdout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1928\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1929\u001b[0;31m                 return inner_training_loop(\n\u001b[0m\u001b[1;32m   1930\u001b[0m                     \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1931\u001b[0m                     \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2278\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccumulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2279\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2281\u001b[0m                 if (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   3316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3317\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3318\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3320\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-120-9f509c2b346a>\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m     19\u001b[0m       \u001b[0mseq_log_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_probs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[0;34m]\u001b[0m     \u001b[0;31m# Log probs for the current sequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m       \u001b[0mseq_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[0;34m]\u001b[0m           \u001b[0;31m# True labels for the current sequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m       \u001b[0mseq_role_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrole_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[0;34m]\u001b[0m       \u001b[0;31m# Role identifiers for the current sequence (assistant/user)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m       \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[0;34m]\u001b[0m              \u001b[0;31m# Reward for the current sequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": [],
      "history_visible": true,
      "gpuType": "T4",
      "include_colab_link": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f525d64631c34235b286a043fbc996ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_48587a9b43e84380ba8596b3e56e7f79",
              "IPY_MODEL_043b24de404846d29e0d16e78e1a74df",
              "IPY_MODEL_aa007d625b454f2499b9dc2acb977a33",
              "IPY_MODEL_a4346279e3d74718b31e01e6c3db028a",
              "IPY_MODEL_808be3cdeadc4d979bb91b432a76130a"
            ],
            "layout": "IPY_MODEL_c3578bef74de4f40896f9fd4bd5d6c9e"
          }
        },
        "48587a9b43e84380ba8596b3e56e7f79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd466f5a7464431b9445f095888cf331",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_ddd8515e42564c8cb99f350335bed4b2",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "043b24de404846d29e0d16e78e1a74df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_8d30d2a849a547dba4aa14cf90a9f64c",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_0311375d26b04f7c8603323a243ad11a",
            "value": ""
          }
        },
        "aa007d625b454f2499b9dc2acb977a33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_af8044c79f44437a8e8be607802947a2",
            "style": "IPY_MODEL_c87d4a33fbf945d3af3644709e012107",
            "value": true
          }
        },
        "a4346279e3d74718b31e01e6c3db028a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_87ac318249954581a64a50f7a83bf6b8",
            "style": "IPY_MODEL_e218fe3cb6c94ef1bd71a9c4a31b0d71",
            "tooltip": ""
          }
        },
        "808be3cdeadc4d979bb91b432a76130a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d84afbcb6eda46cbb40b66e84f353862",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_95947a14e94642d18c9741de8dedb79e",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "c3578bef74de4f40896f9fd4bd5d6c9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "fd466f5a7464431b9445f095888cf331": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ddd8515e42564c8cb99f350335bed4b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8d30d2a849a547dba4aa14cf90a9f64c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0311375d26b04f7c8603323a243ad11a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "af8044c79f44437a8e8be607802947a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c87d4a33fbf945d3af3644709e012107": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "87ac318249954581a64a50f7a83bf6b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e218fe3cb6c94ef1bd71a9c4a31b0d71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "d84afbcb6eda46cbb40b66e84f353862": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95947a14e94642d18c9741de8dedb79e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}